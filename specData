#!/usr/bin/python
'''
General plan:
    use scikits.audiolab to get data bit by bit
    fft the samples --> get the spectrum
'''
import numpy as np
from scikits.audiolab import Sndfile
import sys

#### Some extra-info
#
# human hearing ~20hz - ~20khz
# piano is from ~27hz to ~4200hz
#
####
#### TODO
#       CONVERT ALL THIS TO A CLASS
#######
####### VARIABLES/FUNCTIONS OF DOOM
### TODO
###     deduce the proper variables
###     from the file itself, instead
###     of hardcoding them --- obviously
###     code would need some direction, 
###     but it is too myopic right now 

#pass the uri to the script
audio_file = sys.argv[1]

#total slices or w/e
total_fouriers = 11000

#the window size (i.e., number of samples) for each fft
fourier_window = np.float(1024)


def freqs(sample_size, sample_rate):
    #center frequency for each index
    f = np.true_divide(sample_rate, sample_size)
    p=[k * f for k in range(int(np.floor_divide(sample_size,2) + 1))]
    return p

def freq_to_bound(sample_size, sample_rate):
    #now I need to determine for the indices where they belong in the bounds
    # basically, a mapping of fft index to blended band index

    # really stupid way to do this, but wtf, I suck at coding
    # TODO
    #   optimize, unnecessary tests
    indices=[]
    for j,bound in enumerate(bounds(sample_rate)):
        inds = []
        for i,freq in enumerate(freqs(sample_size, sample_rate)):
            if bound[0] <= freq <= bound[1]:
                #print freq, "w/i", bound[0], "and", bound[1]
                #print "--> therefore,", i, "in", j
                inds.append(i)
            if freq > bound[1]:
                break
        indices.append(inds)

    return indices

def bandwidth(sample_size, sample_rate):
    #return bandwidth
    return np.multiply(np.true_divide(2, sample_size), np.true_divide(sample_rate, 2))

####### END VARIABLES/FUNCTIONS OF DOOM


########### GET THE AUDIO DATA

f = Sndfile(audio_file, "r")

# some germane
# f properties..
    #   samplerate = samplerate of the file
    #   nframes = total number of frames in the file
    #   channels = number of channels in the file
#   methods...
    #   read_frames(x) = read x number of frames, moves index
    #   seek(x) = move to frame number x

#length of file (in secs) very rough
time_length = f.nframes / f.samplerate

# fouriers per second of sample
fouriers_per_second = total_fouriers / time_length

#frame step between each fft
fourier_step = np.floor_divide(f.nframes, total_fouriers)

##### print the info, if one wants
#print "samplerate:",f.samplerate
#print "total frames:",f.nframes
#print "window_size:",fourier_window
#print "# of ffts:", total_fouriers
#print "step:",fourier_step
#print "length:", time_length, "seconds"
######

# go through parts of file, chunk by chunk, with seeks
# TODO
#   optimize when fourier_step is below fourier_window
#   since it crazy slows down -- don't know why maybe backwards
#   seeks are slow? e.g., 1000 ---> 998 = slow, but 998 --> 1000 = fast?
print "starting audio chunking"
i=0
spec_data = []
for window in range(total_fouriers):
    f.seek(i)
    if f.channels == 1:
        chunk = f.read_frames(fourier_window)

    else:
        #average the channels
        chunk = np.mean(f.read_frames(fourier_window), axis=1)

    spec_data.append(chunk)
    i+=fourier_step

##### Have spectrum audio data in array, yay!!!!

print "finished audio retrieval, fft now"
# fft it and take its abs
fft_data = np.abs(np.fft.rfft(spec_data))
print "fft done"

##### Now we need to blend into bands
# average for each fft
print "blending starting"
a = []
for s in freq_to_bound(fourier_window, f.samplerate):
    #TODO 
    #   i can (should?) append zeros if no frequency center
    #   is in the band, however that doesn't mean
    #   there isn't some spectral density...
    #   i'll think about it if i ever want to change this
    #   since i should use the bandwidth function to see how
    #   wide (in hz) the spectral data is and then intelligently
    #   add it to 1+ bands, if it spills over into other blended bands
    if s:
        a.append( 
                    #average every fft between bounds
                    np.mean(
                        fft_data[...,s[0]:s[-1]+1], 
                        axis=1
                        )
                    )
    else:
       #a.append(
       #            #add zeroes since no data in that band 
       #            np.zeros(( total_fouriers,))
       #        )
        continue


# join the averages
a = np.dstack(a)[0]
print "done blending"

##### this previous part was hard to explain w/o some visuals 

##### we are going to write to a file
#import json
from StringIO import StringIO
fp = StringIO()

# write part of desired format, 
# probably can do this through json.dump
# but i'm just copying that stupid non-json shit
fp.write("data[0] = {title: 'blar', timecode: [")

# calculate very roughly millisecond difference b/w each sample
time_step = np.reciprocal(np.float(fouriers_per_second)) * 1000
#print time_step, "ms b/w each sampling"

# time window for each sample set (in ms)
window_time = (time_length / fourier_window) * 1000
#print window_time, "ms for each sample set"

#find max value and scale ratio in fft, needed for scaling
high=np.amax(a)
scale = 255 / high # (high - low) but low = 0, more or less

center = window_time / 2

for k,v in enumerate(a):
    # calculte time (in ms) for each sample
    time = int(np.floor((k * time_step) + center))
    #print time, "milliseconds"

    #scale values to between 0-255
    tmp = np.multiply(v, scale)
    tmp = np.round(tmp)
    tmp = np.asarray(tmp,dtype=int)

    # write to file object
    fp.write('{t:' + str(time) + ',p:' + str(tmp.tolist()) + '}')
    if k == len(a) - 1:
        continue
    else:
        fp.write(',')

fp.write("]};")
contents = fp.getvalue()
fp.close()

# write to file
with open("/home/cz/d.txt", "w") as p:
    p.write(contents)

##### Done writing to file
